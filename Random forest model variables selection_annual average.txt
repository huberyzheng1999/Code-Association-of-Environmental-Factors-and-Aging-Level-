import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from scipy.stats import spearmanr
import warnings
import os

warnings.filterwarnings('ignore')

DATA_PATH = 'C:/â€¦â€¦'
SAVE_IMPORTANCE_PATH = 'C:/â€¦â€¦'
SAVE_PLOT_PATH = 'C:/â€¦â€¦'
SAVE_VALIDATION_SUMMARY = 'C:/â€¦â€¦'

os.makedirs(SAVE_PLOT_PATH, exist_ok=True)

ID_VARS = ['pac', 'Year', 'Urb']
TARGET_VARS = ['LA65', 'LA85']

FEATURES = [â€¦â€¦]
URBAN_GROUPS = ['ä½åŸå¸‚åŒ–ç»„', 'ä¸­åŸå¸‚åŒ–ç»„', 'é«˜åŸå¸‚åŒ–ç»„']
QUANTILE_THRESHOLD = 0.01

RF_PARAMS = {
    'n_estimators': 100,
    'max_depth': 10,
    'min_samples_split': 5,
    'random_state': 42,
    'n_jobs': -1,
    'oob_score': True  
}

REPEAT_TIMES = 3
RANDOM_SEEDS = [42, 123, 456]

def load_data(path):
    df = pd.read_excel(path)
    print(f"åŸå§‹æ•°æ®åˆ—å: {df.columns.tolist()}")
    print(f"æ£€æŸ¥æ˜¯å¦æœ‰'Urb'åˆ—: {'Urb' in df.columns}")

    if 'Urb' in df.columns:
        df['Urb_Group'] = pd.cut(df['Urb'], bins=[-1, 3, 7, 10], labels=URBAN_GROUPS)
        print(f"åŸå¸‚åŒ–åˆ†ç»„åˆ›å»ºå®Œæˆï¼Œå„ç»„æ ·æœ¬é‡:")
        print(df['Urb_Group'].value_counts())
    else:
        print("é”™è¯¯ï¼šæ•°æ®ä¸­æ²¡æœ‰'Urb'åˆ—")
        possible_cols = [col for col in df.columns if 'urb' in col.lower() or 'åŸå¸‚åŒ–' in col]
        if possible_cols:
            print(f"æ‰¾åˆ°å¯èƒ½çš„åˆ—: {possible_cols}")
            df['Urb_Group'] = pd.cut(df[possible_cols[0]], bins=[-1, 3, 7, 10], labels=URBAN_GROUPS)
        else:
            raise KeyError("æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°åŸå¸‚åŒ–ç›¸å…³çš„åˆ—")

    all_needed_cols = ID_VARS + TARGET_VARS + FEATURES + ['Urb_Group']
    existing_cols = [col for col in all_needed_cols if col in df.columns]
    df = df[existing_cols]

    print(f"åˆå¹¶æ•°æ®åŠ è½½å®Œæˆï¼šå…±{len(df)}è¡Œï¼Œ{len(df.columns)}åˆ—")
    return df


def handle_outliers(df, features, group_col='Urb_Group', quantile=0.01):

    df_out = df.copy()
    if group_col not in df_out.columns:
        print(f"è­¦å‘Šï¼šæ•°æ®ä¸­æ²¡æœ‰'{group_col}'åˆ—ï¼Œè·³è¿‡åˆ†ç»„å¤„ç†")
        return df_out

    for group in df_out[group_col].unique():
        if pd.isna(group):
            continue
        group_mask = df_out[group_col] == group
        for feat in features:
            if feat not in df_out.columns:
                continue
            group_data = df_out.loc[group_mask, feat]
            if len(group_data) > 0:
                lower = group_data.quantile(quantile)
                upper = group_data.quantile(1 - quantile)
                df_out.loc[group_mask, feat] = group_data.clip(lower=lower, upper=upper)
    print("æç«¯å€¼ç¼©å°¾å¤„ç†å®Œæˆ")
    return df_out


def impute_missing(df, features):

    numeric_features = [f for f in features if f in df.columns and pd.api.types.is_numeric_dtype(df[f])]
    if len(numeric_features) == 0:
        print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°æ•°å€¼å‹ç‰¹å¾è¿›è¡Œæ’è¡¥")
        return df

    imputer = IterativeImputer(random_state=42, max_iter=10)
    df_imputed = df.copy()
    df_imputed[numeric_features] = imputer.fit_transform(df_imputed[numeric_features])
    print(f"ç¼ºå¤±å€¼è¿­ä»£æ’è¡¥å®Œæˆï¼Œå¤„ç†äº†{len(numeric_features)}ä¸ªç‰¹å¾")
    return df_imputed

def calculate_fitting_metrics(model, X, y):

    y_pred = model.predict(X)
    r2 = np.round(r2_score(y, y_pred), 4).item()
    mae = np.round(mean_absolute_error(y, y_pred), 4).item()
    mse = np.round(mean_squared_error(y, y_pred), 4).item()
    return {'è®­ç»ƒé›†RÂ²': r2, 'MAE': mae, 'MSE': mse}

def calculate_importance_consistency(X, y, features, n_repeats=REPEAT_TIMES, seeds=RANDOM_SEEDS):

    importance_rank_list = []
    for seed in seeds:
        params = RF_PARAMS.copy()
        params['random_state'] = seed
        rf = RandomForestRegressor(**params)
        rf.fit(X, y)
        imp_df = pd.DataFrame({'å˜é‡å': features, 'é‡è¦æ€§': rf.feature_importances_})
        imp_df = imp_df.sort_values('é‡è¦æ€§', ascending=False).reset_index(drop=True)
        importance_rank_list.append(imp_df['å˜é‡å'].tolist())

    consistency_scores = []
    for i in range(n_repeats):
        for j in range(i + 1, n_repeats):
            rank_i = pd.Series(range(1, len(features) + 1), index=importance_rank_list[i])
            rank_j = pd.Series(range(1, len(features) + 1), index=importance_rank_list[j])

            rank_i_vals = rank_i[features].values
            rank_j_vals = rank_j[features].values
            valid_mask = ~(np.isnan(rank_i_vals) | np.isnan(rank_j_vals))

            if not np.any(valid_mask):
                corr = np.nan
            else:
                res = spearmanr(rank_i_vals[valid_mask], rank_j_vals[valid_mask])
                corr = res.statistic

            consistency_scores.append(np.round(corr, 4).item() if not np.isnan(corr) else np.nan)

    valid_scores = [s for s in consistency_scores if not np.isnan(s)]
    avg_consistency = np.round(np.mean(valid_scores), 4).item() if valid_scores else np.nan
    return {'é‡è¦æ€§æ’åºä¸€è‡´æ€§ï¼ˆå¹³å‡Spearmanï¼‰': avg_consistency}

def train_group_rf_with_validation(df, target, group_col='Urb_Group'):
    all_importance = []
    validation_summary = []

    for group in URBAN_GROUPS:
        group_data = df[df[group_col] == group].copy()
        if len(group_data) < 30:
            print(f"âš ï¸ {group}ï¼ˆ{target}ï¼‰æ ·æœ¬é‡ä¸è¶³{len(group_data)}ï¼Œè·³è¿‡")
            continue

        available_features = [f for f in FEATURES if f in group_data.columns]
        if len(available_features) == 0:
            print(f"âš ï¸ {group}ï¼ˆ{target}ï¼‰æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—ï¼Œè·³è¿‡")
            continue

        X = group_data[available_features].copy()
        y = group_data[target].copy()

        rf_main = RandomForestRegressor(**RF_PARAMS)
        rf_main.fit(X, y)

        oob_r2 = np.round(rf_main.oob_score_, 4).item() if (
                hasattr(rf_main, 'oob_score_') and not np.isnan(rf_main.oob_score_)) else np.nan
        fitting_metrics = calculate_fitting_metrics(rf_main, X, y)
        consistency_metrics = calculate_importance_consistency(X, y, available_features)

        imp_df = pd.DataFrame({
            'åŸå¸‚åŒ–åˆ†ç»„': group,
            'å› å˜é‡': target,
            'å˜é‡å': available_features,
            'å˜é‡é‡è¦æ€§': rf_main.feature_importances_,
            'é‡è¦æ€§å æ¯”(%)': np.round(rf_main.feature_importances_ * 100, 2),
            'OOB-RÂ²': oob_r2,
            'è®­ç»ƒé›†RÂ²': fitting_metrics['è®­ç»ƒé›†RÂ²'],
            'MAE': fitting_metrics['MAE']
        })
        imp_df = imp_df.sort_values('å˜é‡é‡è¦æ€§', ascending=False).reset_index(drop=True)
        all_importance.append(imp_df)

        val_summary = {
            'åŸå¸‚åŒ–åˆ†ç»„': group,
            'å› å˜é‡': target,
            'æ ·æœ¬é‡': len(group_data),
            'OOB-RÂ²': oob_r2,
            'è®­ç»ƒé›†RÂ²': fitting_metrics['è®­ç»ƒé›†RÂ²'],
            'MAE': fitting_metrics['MAE'],
            'MSE': fitting_metrics['MSE'],
            'å˜é‡é‡è¦æ€§æ’åºä¸€è‡´æ€§ï¼ˆå¹³å‡Spearmanï¼‰': consistency_metrics['é‡è¦æ€§æ’åºä¸€è‡´æ€§ï¼ˆå¹³å‡Spearmanï¼‰']
        }
        validation_summary.append(val_summary)

        plot_top_importance(imp_df.head(15), group, target)
        print(
            f"âœ… {group}ï¼ˆ{target}ï¼‰è®­ç»ƒå®Œæˆï¼šOOB-RÂ²={oob_r2}ï¼Œæ’åºä¸€è‡´æ€§={val_summary['å˜é‡é‡è¦æ€§æ’åºä¸€è‡´æ€§ï¼ˆå¹³å‡Spearmanï¼‰']}")

    return pd.concat(all_importance, ignore_index=True) if all_importance else pd.DataFrame(), \
        pd.DataFrame(validation_summary) if validation_summary else pd.DataFrame()


def plot_top_importance(importance, group, target):
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    plt.figure(figsize=(12, 8))
    bars = plt.barh(importance['å˜é‡å'][::-1], importance['é‡è¦æ€§å æ¯”(%)'][::-1], color='#1f77b4')
    for bar in bars:
        width = bar.get_width()
        plt.text(width + 0.1, bar.get_y() + bar.get_height() / 2,
                 f'{width:.1f}%', ha='left', va='center', fontsize=9)
    plt.title(f'Variable Importance (Merged Data) - {group} ({target})', fontsize=14, fontweight='bold')
    plt.xlabel('Importance (%)', fontsize=12)
    plt.ylabel('Variables', fontsize=12)
    plt.tight_layout()

    safe_group = group.replace('/', '_').replace('\\', '_')
    safe_target = target.replace('/', '_').replace('\\', '_')
    filename = f'{SAVE_PLOT_PATH}{safe_group}_{safe_target}_importance.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"å›¾è¡¨å·²ä¿å­˜: {filename}")

def main_group_rf():
    df = load_data(DATA_PATH)
    print(f"\næ•°æ®æ¦‚è§ˆ: {df.shape}")
    df = handle_outliers(df, FEATURES)
    df = impute_missing(df, FEATURES)

    all_importance = []
    all_validation = []

    for target in TARGET_VARS:
        print(f"\n=== å¼€å§‹å¤„ç†å› å˜é‡ï¼š{target} ===")
        if target not in df.columns:
            print(f"âš ï¸ ç›®æ ‡å˜é‡{target}ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        imp_df, val_df = train_group_rf_with_validation(df, target)
        if not imp_df.empty:
            all_importance.append(imp_df)
        if not val_df.empty:
            all_validation.append(val_df)

    if all_importance:
        final_importance = pd.concat(all_importance, ignore_index=True)
        final_importance.to_excel(SAVE_IMPORTANCE_PATH, index=False)
        print(f"\nğŸ‰ åˆå¹¶æ•°æ®å˜é‡é‡è¦æ€§ç»“æœå·²ä¿å­˜è‡³ï¼š{SAVE_IMPORTANCE_PATH}")
    else:
        print("\nâš ï¸ æ²¡æœ‰ç”Ÿæˆå˜é‡é‡è¦æ€§ç»“æœ")

    if all_validation:
        final_validation = pd.concat(all_validation, ignore_index=True)
        final_validation.to_excel(SAVE_VALIDATION_SUMMARY, index=False)
        print(f"ğŸ‰ åˆå¹¶æ•°æ®æ¨¡å‹éªŒè¯æ±‡æ€»è¡¨å·²ä¿å­˜è‡³ï¼š{SAVE_VALIDATION_SUMMARY}")
        print("\n=== æ¨¡å‹éªŒè¯æ±‡æ€»é¢„è§ˆ ===")
        print(final_validation[['åŸå¸‚åŒ–åˆ†ç»„', 'å› å˜é‡', 'æ ·æœ¬é‡', 'OOB-RÂ²', 'è®­ç»ƒé›†RÂ²',
                                'å˜é‡é‡è¦æ€§æ’åºä¸€è‡´æ€§ï¼ˆå¹³å‡Spearmanï¼‰']].head())
    else:
        print("\nâš ï¸ æœªç”Ÿæˆæ¨¡å‹éªŒè¯æ±‡æ€»è¡¨")


if __name__ == '__main__':
    main_group_rf()
